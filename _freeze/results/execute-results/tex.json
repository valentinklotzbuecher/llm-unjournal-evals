{
  "hash": "4d7f72325c9b393d61d77c2707ef48c3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Results\"\nformat: \n  html: default\n  # pdf: default\nengine: knitr\n--- \n\n::: {.cell}\n\n:::\n\n\n\n\n\n\nHere we present preliminary results, starting with a comparison of the LLM‑generated quantitative ratings (model: `gpt-5-pro`, see the[(previous section](methods.qmd)) with human evaluations across [the Unjournal's criteria](https://globalimpact.gitbook.io/the-unjournal-project-and-communication-space/policies-projects-evaluation-workflow/evaluation/guidelines-for-evaluators#undefined-1). \n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Quantitative comparison: human vs. GPT‑5 Pro\n\nWe first use the earlier GPT‑5 Pro evaluation run that covered all papers in our Unjournal sample with a simpler JSON‑schema prompt. @fig-forest-overall shows the overall percentile ratings from this initial run, averaged across human evaluators and compared to the LLM’s “overall” scores for each paper.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of Human vs LLM overall percentile ratings](results_files/figure-pdf/fig-forest-overall-1.pdf){#fig-forest-overall}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparison of Human vs LLM journal tier ratings (should be published in)](results_files/figure-pdf/fig-forest-tiers-should-1.pdf){#fig-forest-tiers-should}\n:::\n:::\n\n\n\n@fig-heatmap-human-minus-llm shows a heatmap of the differences between human and LLM mean ratings across all evaluation criteria. Positive values (in green) indicate that humans rated the paper higher than the LLM, while negative values (in orange) indicate the opposite.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Heatmap of Human minus LLM mean ratings across evaluation criteria](results_files/figure-pdf/fig-heatmap-human-minus-llm-1.pdf){#fig-heatmap-human-minus-llm}\n:::\n:::\n\n\n\n\n\n::: {.columns}\n\n::: {.column width=\"75%\"}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](results_files/figure-pdf/scatter-overall-static-stats-1.pdf)\n:::\n:::\n\n\n\n\n:::\n\n::: {.column width=\"25%\"}\n\n\n- Matched papers: 47\n- Pearson r: 0.37\n- Spearman rho: 0.50\n- Krippendorff α (interval): 0.02\n- MAE (points): 13.2\n\n:::\n\n\n:::\n\n\n\\clearpage\n\n## Qualitative comparison: detailed GPT‑5 Pro evaluations\n\nTo understand what GPT‑5 Pro is actually responding to, we re‑ran the model on four focal papers [@Adena2024; @Peterman2024; @Green2025; @Williams2024] using a refined prompt.\n\nThis second run keeps the same quantitative metrics but additionally requires a diagnostic summary of about 1,000 words and high‑effort reasoning, with the full reasoning trace returned by the “thinking” model. For each paper we can therefore inspect:\n\n- the LLM’s quantitative scores and journal‑tier predictions,\n- the hidden reasoning steps used to arrive at those scores, and\n- the token usage and approximate API cost of the evaluation.\n\nWe start by examining the Williams et al. (2024) evaluation in detail and then show the analogous summaries for the other four focal papers. In the next step we will juxtapose these LLM assessments with the human evaluators’ written reports.\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Paper                | Input tokens| Output tokens| Reasoning tokens| Total tokens| Est. cost (USD)|\n|:--------------------|------------:|-------------:|----------------:|------------:|---------------:|\n|Peterman et al. 2025 |        18762|          7617|             6208|        26379|            1.94|\n|Adena and Hager 2024 |        24234|          7019|             5312|        31253|            1.84|\n|Williams et al. 2024 |        28704|          6327|             5120|        35031|            1.80|\n|Kudymowa et al. 2023 |        65096|          4147|             2432|        69243|            1.77|\n|Green et al. 2025    |        22904|          5884|             3904|        28788|            1.52|\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n### Qualitative comparison: Williams et al. (2024)\n\nIn the refined run, GPT‑5 Pro reads about \n28,704 input tokens and produces \n6,327 visible output tokens plus \n5,120 reasoning tokens.  \nAt current API prices this evaluation costs roughly \n$1.80.\n\nThe table below shows the model’s percentile ratings and 90% credible intervals for the Unjournal criteria.\n\n\n\n\n\n::: {#tbl-llm-williams-metrics .cell tbl-cap='GPT-5 Pro percentile ratings for Williams et al. (2024)'}\n\n\\begin{longtable}[t]{lccc}\n\\toprule\nCriterion & Midpoint & Lower 90\\% & Upper 90\\%\\\\\n\\midrule\nOverall assessment & 86 & 86 & 86\\\\\nClaims \\& evidence & 78 & 78 & 78\\\\\nMethods & 74 & 74 & 74\\\\\nAdvancing knowledge and practice & 92 & 92 & 92\\\\\nLogic and communication & 84 & 84 & 84\\\\\n\\addlinespace\nOpen, collaborative, replicable science & 63 & 63 & 63\\\\\nRelevance to global priorities & 94 & 94 & 94\\\\\n\\bottomrule\n\\end{longtable}\n:::\n\n::: {#tbl-llm-williams-tiers .cell tbl-cap='GPT-5 Pro journal tier ratings for Williams et al. (2024)'}\n\n\\begin{longtable}[t]{lccc}\n\\toprule\nMeasure & Score & Lower 90\\% & Upper 90\\%\\\\\n\\midrule\nDeserved journal tier (should) & 4.4 & 4.4 & 4.4\\\\\nPredicted journal tier (will) & 4.8 & 4.8 & 4.8\\\\\n\\bottomrule\n\\end{longtable}\n:::\n\n\n\nFor Williams et al. (2024), GPT‑5 Pro assigns a high overall percentile score (86/100), with particularly strong ratings for advancing knowledge (92) and global relevance (94), and a relatively favourable view of methods (74) and claims and evidence (78). It judges the paper as deserving publication in a high‑tier journal (tier‑should 4.4/5, tier‑will 4.8/5). \n\nIn its diagnostic summary and reasoning trace (printed below), the model identifies many of the same issues highlighted by the human evaluators: heavy reliance on a regrowth dataset with low producer accuracy and substantial omission error; temporal leakage from contemporaneous predictors; uncalibrated random‑forest probabilities used to derive the 215 Mha estimate; unrealistically narrow confidence intervals; coarse predictors driving 30‑m predictions; a liberal definition of land “available for restoration”; and incomplete uncertainty quantification for the carbon overlay and permanence. It also notes that code is not fully open, limiting replication despite open data and published maps.\n\nBy contrast, both human evaluators at The Unjournal assign much lower overall ratings (50/100) and are substantially more critical of methods and claims: methods scores of 20 and 5, and claims scores of 20 and 5, respectively. They explicitly argue that methodological problems “fundamentally challenge the validity and utility of the central 215 Mha estimate of regeneration potential,” even while rating the paper’s contribution to knowledge and global relevance as high and considering it suitable for high‑tier journals conditional on major revisions.\n\nQualitatively, the LLM and human experts are strikingly aligned on what the main problems are: they converge on concerns about biased input data, temporal leakage, incomplete probability calibration, under‑stated uncertainty, domain definition, and the gap between “biophysical potential” and realistic policy use. However, they diverge sharply on how serious these problems are. The human evaluators treat them as sufficient to render the headline estimates low‑credibility and heavily qualified for policy use; GPT‑5 Pro instead regards these issues as important but ultimately compatible with a high overall rating, robust methods, and near top‑journal quality.\n\nThis case suggests that, at least in this configuration, the LLM can reproduce sophisticated methodological critiques and uncertainty language but tends to under‑penalise these shortcomings in its quantitative ratings, especially for high‑profile, high‑impact work.\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}